{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["rxXJmwyYwEkh","caq3q_SUwhPg"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# MODIS EVI - Training second set of models"],"metadata":{"id":"VbZ6-PhbvMf1"}},{"cell_type":"markdown","source":["## Importing Cleaned Data"],"metadata":{"id":"7e1qG9VTv05i"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q1jAtUyXvLit","executionInfo":{"status":"ok","timestamp":1724539347896,"user_tz":300,"elapsed":23278,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"cc9b5ec2-5084-4f19-e6fe-9e9138c64d3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/  # change this to the root working directory"]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"ZMB1bjdDvQ1Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path = 'Modeling VIs in Tallgrass/data/P13_Cleaned_Data.csv'\n","df = pd.read_csv(file_path)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":635},"id":"vkxcmpYjvQ4d","executionInfo":{"status":"ok","timestamp":1724539353134,"user_tz":300,"elapsed":1510,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"b3558d80-38c1-4e78-c5c5-5b7b39c4db10"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Unnamed: 0        DATE  Tavg_mean  Havg_mean  Vdef_mean  Hdeg_mean  \\\n","0              6  2000-02-18   52.10875   71.93625    4.46000   12.16500   \n","1              7  2000-02-26   48.71250   66.61750    5.25500   16.66875   \n","2              8  2000-03-05   50.03750   72.90625    4.11375   14.25750   \n","3              9  2000-03-13   47.88250   81.58250    3.14125   15.82625   \n","4             10  2000-03-21   57.95000   75.16625    5.15500    6.97000   \n","...          ...         ...        ...        ...        ...        ...   \n","1069        1090  2023-09-14   71.42375   73.00250    8.62500    0.00000   \n","1070        1091  2023-09-22   75.57250   66.09000   12.62500    0.00000   \n","1071        1092  2023-09-30   68.66625   63.53250   10.45000    2.35625   \n","1072        1093  2023-10-08   61.79500   65.17125    7.83500    4.42000   \n","1073        1094  2023-10-16   62.97125   56.99625   11.08000    3.90000   \n","\n","      Cdeg_mean  Wspd_mean  Atot_mean  Rain_sum  Savg_mean  Bavg_mean  \\\n","0       0.00000   14.49375  13.258750      1.06   50.37625   50.81500   \n","1       0.00000   12.51125  14.832385      0.78   49.21875   49.43125   \n","2       0.00000   13.49750  17.770000      0.71   51.34375   51.30125   \n","3       0.00000   10.42750  12.791250      0.95   50.05750   49.97750   \n","4       0.00000   10.11750  16.667500      2.39   56.53125   56.36875   \n","...         ...        ...        ...       ...        ...        ...   \n","1069    6.97375    8.59875  15.427500      0.99   71.31000   71.28000   \n","1070   11.76625    9.57000  18.105000      0.39   72.30125   75.01625   \n","1071    7.10750    8.96625  15.098750      1.52   69.67000   72.41000   \n","1072    1.91250   12.27000  15.991250      0.00   64.46500   64.92125   \n","1073    2.79500    8.68625  15.016250      0.00   61.04500   64.09625   \n","\n","      Tr05_mean  Tr25_mean  Tr60_mean  MODIS_EVI   LSWI  \n","0      1.863600   1.581400   1.504100      0.254 -0.111  \n","1      1.671738   1.570663   1.491400      0.211 -0.136  \n","2      1.562450   1.557400   1.478662      0.231 -0.092  \n","3      1.594888   1.547525   1.471650      0.170 -0.205  \n","4      1.507513   1.531750   1.465475      0.187 -0.206  \n","...         ...        ...        ...        ...    ...  \n","1069   1.520763   3.208450   3.473537      0.379  0.084  \n","1070   1.620875   2.699000   3.452688      0.446  0.163  \n","1071   1.813212   2.058113   3.441438      0.426  0.125  \n","1072   1.711912   1.664287   3.413925      0.401  0.105  \n","1073   2.037275   1.918113   3.415062      0.399  0.131  \n","\n","[1074 rows x 17 columns]"],"text/html":["\n","  <div id=\"df-839aed53-8821-470e-b8b9-00a1ccbd0cf7\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>DATE</th>\n","      <th>Tavg_mean</th>\n","      <th>Havg_mean</th>\n","      <th>Vdef_mean</th>\n","      <th>Hdeg_mean</th>\n","      <th>Cdeg_mean</th>\n","      <th>Wspd_mean</th>\n","      <th>Atot_mean</th>\n","      <th>Rain_sum</th>\n","      <th>Savg_mean</th>\n","      <th>Bavg_mean</th>\n","      <th>Tr05_mean</th>\n","      <th>Tr25_mean</th>\n","      <th>Tr60_mean</th>\n","      <th>MODIS_EVI</th>\n","      <th>LSWI</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>2000-02-18</td>\n","      <td>52.10875</td>\n","      <td>71.93625</td>\n","      <td>4.46000</td>\n","      <td>12.16500</td>\n","      <td>0.00000</td>\n","      <td>14.49375</td>\n","      <td>13.258750</td>\n","      <td>1.06</td>\n","      <td>50.37625</td>\n","      <td>50.81500</td>\n","      <td>1.863600</td>\n","      <td>1.581400</td>\n","      <td>1.504100</td>\n","      <td>0.254</td>\n","      <td>-0.111</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7</td>\n","      <td>2000-02-26</td>\n","      <td>48.71250</td>\n","      <td>66.61750</td>\n","      <td>5.25500</td>\n","      <td>16.66875</td>\n","      <td>0.00000</td>\n","      <td>12.51125</td>\n","      <td>14.832385</td>\n","      <td>0.78</td>\n","      <td>49.21875</td>\n","      <td>49.43125</td>\n","      <td>1.671738</td>\n","      <td>1.570663</td>\n","      <td>1.491400</td>\n","      <td>0.211</td>\n","      <td>-0.136</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>2000-03-05</td>\n","      <td>50.03750</td>\n","      <td>72.90625</td>\n","      <td>4.11375</td>\n","      <td>14.25750</td>\n","      <td>0.00000</td>\n","      <td>13.49750</td>\n","      <td>17.770000</td>\n","      <td>0.71</td>\n","      <td>51.34375</td>\n","      <td>51.30125</td>\n","      <td>1.562450</td>\n","      <td>1.557400</td>\n","      <td>1.478662</td>\n","      <td>0.231</td>\n","      <td>-0.092</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9</td>\n","      <td>2000-03-13</td>\n","      <td>47.88250</td>\n","      <td>81.58250</td>\n","      <td>3.14125</td>\n","      <td>15.82625</td>\n","      <td>0.00000</td>\n","      <td>10.42750</td>\n","      <td>12.791250</td>\n","      <td>0.95</td>\n","      <td>50.05750</td>\n","      <td>49.97750</td>\n","      <td>1.594888</td>\n","      <td>1.547525</td>\n","      <td>1.471650</td>\n","      <td>0.170</td>\n","      <td>-0.205</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10</td>\n","      <td>2000-03-21</td>\n","      <td>57.95000</td>\n","      <td>75.16625</td>\n","      <td>5.15500</td>\n","      <td>6.97000</td>\n","      <td>0.00000</td>\n","      <td>10.11750</td>\n","      <td>16.667500</td>\n","      <td>2.39</td>\n","      <td>56.53125</td>\n","      <td>56.36875</td>\n","      <td>1.507513</td>\n","      <td>1.531750</td>\n","      <td>1.465475</td>\n","      <td>0.187</td>\n","      <td>-0.206</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1069</th>\n","      <td>1090</td>\n","      <td>2023-09-14</td>\n","      <td>71.42375</td>\n","      <td>73.00250</td>\n","      <td>8.62500</td>\n","      <td>0.00000</td>\n","      <td>6.97375</td>\n","      <td>8.59875</td>\n","      <td>15.427500</td>\n","      <td>0.99</td>\n","      <td>71.31000</td>\n","      <td>71.28000</td>\n","      <td>1.520763</td>\n","      <td>3.208450</td>\n","      <td>3.473537</td>\n","      <td>0.379</td>\n","      <td>0.084</td>\n","    </tr>\n","    <tr>\n","      <th>1070</th>\n","      <td>1091</td>\n","      <td>2023-09-22</td>\n","      <td>75.57250</td>\n","      <td>66.09000</td>\n","      <td>12.62500</td>\n","      <td>0.00000</td>\n","      <td>11.76625</td>\n","      <td>9.57000</td>\n","      <td>18.105000</td>\n","      <td>0.39</td>\n","      <td>72.30125</td>\n","      <td>75.01625</td>\n","      <td>1.620875</td>\n","      <td>2.699000</td>\n","      <td>3.452688</td>\n","      <td>0.446</td>\n","      <td>0.163</td>\n","    </tr>\n","    <tr>\n","      <th>1071</th>\n","      <td>1092</td>\n","      <td>2023-09-30</td>\n","      <td>68.66625</td>\n","      <td>63.53250</td>\n","      <td>10.45000</td>\n","      <td>2.35625</td>\n","      <td>7.10750</td>\n","      <td>8.96625</td>\n","      <td>15.098750</td>\n","      <td>1.52</td>\n","      <td>69.67000</td>\n","      <td>72.41000</td>\n","      <td>1.813212</td>\n","      <td>2.058113</td>\n","      <td>3.441438</td>\n","      <td>0.426</td>\n","      <td>0.125</td>\n","    </tr>\n","    <tr>\n","      <th>1072</th>\n","      <td>1093</td>\n","      <td>2023-10-08</td>\n","      <td>61.79500</td>\n","      <td>65.17125</td>\n","      <td>7.83500</td>\n","      <td>4.42000</td>\n","      <td>1.91250</td>\n","      <td>12.27000</td>\n","      <td>15.991250</td>\n","      <td>0.00</td>\n","      <td>64.46500</td>\n","      <td>64.92125</td>\n","      <td>1.711912</td>\n","      <td>1.664287</td>\n","      <td>3.413925</td>\n","      <td>0.401</td>\n","      <td>0.105</td>\n","    </tr>\n","    <tr>\n","      <th>1073</th>\n","      <td>1094</td>\n","      <td>2023-10-16</td>\n","      <td>62.97125</td>\n","      <td>56.99625</td>\n","      <td>11.08000</td>\n","      <td>3.90000</td>\n","      <td>2.79500</td>\n","      <td>8.68625</td>\n","      <td>15.016250</td>\n","      <td>0.00</td>\n","      <td>61.04500</td>\n","      <td>64.09625</td>\n","      <td>2.037275</td>\n","      <td>1.918113</td>\n","      <td>3.415062</td>\n","      <td>0.399</td>\n","      <td>0.131</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1074 rows × 17 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-839aed53-8821-470e-b8b9-00a1ccbd0cf7')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-839aed53-8821-470e-b8b9-00a1ccbd0cf7 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-839aed53-8821-470e-b8b9-00a1ccbd0cf7');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-5c2bee93-1ea9-48be-908b-0b10ce1828c7\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5c2bee93-1ea9-48be-908b-0b10ce1828c7')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-5c2bee93-1ea9-48be-908b-0b10ce1828c7 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_796fff2f-9739-4601-b47c-0d319e0e418b\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_796fff2f-9739-4601-b47c-0d319e0e418b button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 1074,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 311,\n        \"min\": 6,\n        \"max\": 1094,\n        \"num_unique_values\": 1074,\n        \"samples\": [\n          550,\n          378,\n          315\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DATE\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1074,\n        \"samples\": [\n          \"2011-12-19\",\n          \"2008-03-21\",\n          \"2006-11-09\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tavg_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.679820945464233,\n        \"min\": 8.6125,\n        \"max\": 92.72875,\n        \"num_unique_values\": 1064,\n        \"samples\": [\n          65.2825,\n          86.42375000000001,\n          48.7825\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Havg_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.07360529808651,\n        \"min\": 32.48625,\n        \"max\": 97.525,\n        \"num_unique_values\": 1051,\n        \"samples\": [\n          79.04,\n          80.66875,\n          80.485\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Vdef_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.452989485619028,\n        \"min\": 0.22,\n        \"max\": 40.06875,\n        \"num_unique_values\": 1020,\n        \"samples\": [\n          7.6625,\n          10.5275,\n          6.72875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hdeg_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.55687076130563,\n        \"min\": 0.0,\n        \"max\": 56.70875,\n        \"num_unique_values\": 746,\n        \"samples\": [\n          4.57375,\n          26.4925,\n          30.095\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cdeg_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.529043205412971,\n        \"min\": 0.0,\n        \"max\": 27.8525,\n        \"num_unique_values\": 643,\n        \"samples\": [\n          15.47,\n          2.35375,\n          18.27125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Wspd_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.295833431984739,\n        \"min\": 4.8575,\n        \"max\": 19.82875,\n        \"num_unique_values\": 1010,\n        \"samples\": [\n          12.56375,\n          7.47875,\n          12.34125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Atot_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.051289215353752,\n        \"min\": 2.58125,\n        \"max\": 29.42875,\n        \"num_unique_values\": 1043,\n        \"samples\": [\n          23.16625,\n          14.395,\n          13.13375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rain_sum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1013882875730945,\n        \"min\": 0.0,\n        \"max\": 8.57,\n        \"num_unique_values\": 291,\n        \"samples\": [\n          0.42,\n          2.3,\n          1.76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Savg_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.51556521058855,\n        \"min\": 34.682500000000005,\n        \"max\": 85.6075,\n        \"num_unique_values\": 1051,\n        \"samples\": [\n          53.72125,\n          69.115,\n          54.67625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bavg_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.053671738290337,\n        \"min\": 30.4375,\n        \"max\": 91.62875,\n        \"num_unique_values\": 1018,\n        \"samples\": [\n          87.79375,\n          46.98125,\n          53.995000000000005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tr05_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6310371309187578,\n        \"min\": 1.3443625,\n        \"max\": 3.9493125,\n        \"num_unique_values\": 1060,\n        \"samples\": [\n          2.271825,\n          1.5923375,\n          2.269675\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tr25_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6980448681813824,\n        \"min\": 1.3278,\n        \"max\": 3.9167625,\n        \"num_unique_values\": 1058,\n        \"samples\": [\n          1.5226375,\n          3.3755875,\n          1.5803250000000002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tr60_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8823787386067834,\n        \"min\": 1.3138625,\n        \"max\": 3.760875,\n        \"num_unique_values\": 1065,\n        \"samples\": [\n          2.20335,\n          3.30795,\n          1.5495625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MODIS_EVI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13549575119980423,\n        \"min\": -0.085,\n        \"max\": 0.664,\n        \"num_unique_values\": 420,\n        \"samples\": [\n          0.179,\n          0.557,\n          0.163\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LSWI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17121302665800833,\n        \"min\": -1.37,\n        \"max\": 1.003,\n        \"num_unique_values\": 492,\n        \"samples\": [\n          -0.293,\n          0.227,\n          0.202\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["df = df.drop(['Unnamed: 0'], axis = 1)"],"metadata":{"id":"EMzzTi7IvQ7g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train and Test Split"],"metadata":{"id":"rxXJmwyYwEkh"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split"],"metadata":{"id":"T3tJHpK5vQ-Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training data from 2000-2021 and testing data from 2022-2023\n","train_test = df[df['DATE'] < '2022-01-01']\n","validation = df[df['DATE'] >= '2022-01-01']"],"metadata":{"id":"o2g6aonuwGWR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = train_test[['Tavg_mean', 'Havg_mean', 'Vdef_mean', 'Hdeg_mean', 'Cdeg_mean',\n","       'Wspd_mean', 'Atot_mean', 'Rain_sum', 'Savg_mean', 'Bavg_mean',\n","       'Tr05_mean', 'Tr25_mean', 'Tr60_mean']]\n","y = train_test[['MODIS_EVI']]"],"metadata":{"id":"vYim-JplwGZ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"Qqusa7KWwGdm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_val = validation[['Tavg_mean', 'Havg_mean', 'Vdef_mean', 'Hdeg_mean', 'Cdeg_mean',\n","       'Wspd_mean', 'Atot_mean', 'Rain_sum', 'Savg_mean', 'Bavg_mean',\n","       'Tr05_mean', 'Tr25_mean', 'Tr60_mean']]\n","y_val = validation[['MODIS_EVI']]"],"metadata":{"id":"vEAXVZd0wV2d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(X_train), len(X_test), len(X_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"izqi8o4KwV7g","executionInfo":{"status":"ok","timestamp":1724539387606,"user_tz":300,"elapsed":2,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"d69ac0c2-2e62-4f90-fd1f-bacb9c3cf07d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(802, 201, 71)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Filter observations where EVI < -0.07\n","filtered_indices = y_test[y_test['MODIS_EVI'] < -0.07].index\n","\n","# Print the indices of filtered observations\n","print(filtered_indices)\n","\n","# Print the specific observations\n","print(y.loc[filtered_indices])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sBV24Ky-y7yV","executionInfo":{"status":"ok","timestamp":1724539388735,"user_tz":300,"elapsed":226,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"a6201183-c859-4bf3-a66a-9136b32b3168"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index([456], dtype='int64')\n","     MODIS_EVI\n","456     -0.085\n"]}]},{"cell_type":"code","source":["# Remove observation with index 456 from X_test and y_test\n","X_test = X_test.drop(index=456)\n","y_test = y_test.drop(index=456)"],"metadata":{"id":"s7LNuLSNy75_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(X_train), len(X_test), len(X_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ALkAjHuy8B6","executionInfo":{"status":"ok","timestamp":1724539393034,"user_tz":300,"elapsed":3,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"0626bf37-e949-426c-97fb-f69bff7b9236"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(802, 200, 71)"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## Training More Models"],"metadata":{"id":"caq3q_SUwhPg"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras"],"metadata":{"id":"yYSKc8lDre8h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import packages\n","from sklearn.linear_model import BayesianRidge\n","from sklearn.linear_model import ElasticNet\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D\n","from tensorflow.keras.layers import SimpleRNN\n","from tensorflow.keras.layers import LSTM\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.model_selection import GridSearchCV\n","import numpy as np"],"metadata":{"id":"X5ri2tGuw06x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Bayesian Ridge"],"metadata":{"id":"RRTz67pdwkZa"}},{"cell_type":"code","source":["# Ensure y_train and y_test are 1D arrays\n","y_train = y_train.to_numpy().flatten()\n","y_test = y_test.to_numpy().flatten()\n","\n","# Train a Bayesian Ridge regression model\n","bayesian_ridge_model = BayesianRidge()\n","bayesian_ridge_model.fit(X_train, y_train)\n","\n","# Make predictions on the testing set\n","y_pred_br = bayesian_ridge_model.predict(X_test)\n","\n","# Calculate the MSE, MAE, RMSE, and R² score on the testing set\n","mse_br_test = mean_squared_error(y_test, y_pred_br)\n","mae_br_test = mean_absolute_error(y_test, y_pred_br)\n","rmse_br_test = mean_squared_error(y_test, y_pred_br, squared=False)\n","r2_br_test = r2_score(y_test, y_pred_br)\n","\n","print('MSE:', mse_br_test)\n","print('MAE:', mae_br_test)\n","print('RMSE:', rmse_br_test)\n","print('R2 score:', r2_br_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ODPmMKdw0-g","executionInfo":{"status":"ok","timestamp":1724539409906,"user_tz":300,"elapsed":158,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"6fb0ea26-234d-4276-c762-fe1e37772308"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE: 0.004103790440592999\n","MAE: 0.0511631998962259\n","RMSE: 0.06406083390491416\n","R2 score: 0.7652426671878233\n"]}]},{"cell_type":"code","source":["# Tuned\n","# Define parameter grid\n","\n","# Define the model\n","bayesian_ridge_model = BayesianRidge()\n","\n","# Define the parameter grid\n","param_grid = {\n","    'max_iter': [100, 200, 300],\n","    'alpha_1': [1e-6, 1e-5, 1e-4],\n","    'alpha_2': [1e-5, 1e-4, 1e-3],\n","    'lambda_1': [1e-5, 1e-4, 1e-3],\n","    'lambda_2': [1e-5, 1e-4, 1e-3],\n","    'tol': [1e-4, 1e-3, 1e-2]\n","}\n","\n","# Set up GridSearchCV\n","grid_search = GridSearchCV(estimator=bayesian_ridge_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n","\n","# Fit the model using grid search\n","grid_search.fit(X_train, y_train)\n","\n","# Get the best model from grid search\n","tuned_br_best_model = grid_search.best_estimator_\n","\n","# Make predictions on the testing set\n","y_pred_br_tuned = tuned_br_best_model.predict(X_test)\n","\n","# Calculate the MSE, MAE, RMSE, and R² score on the testing set\n","mse_br_tuned_test = mean_squared_error(y_test, y_pred_br_tuned)\n","mae_br_tuned_test = mean_absolute_error(y_test, y_pred_br_tuned)\n","rmse_br_tuned_test = mean_squared_error(y_test, y_pred_br_tuned, squared=False)\n","r2_br_tuned_test = r2_score(y_test, y_pred_br_tuned)\n","\n","print('Best Parameters:', grid_search.best_params_)\n","print('MSE:', mse_br_tuned_test)\n","print('MAE:', mae_br_tuned_test)\n","print('RMSE:', rmse_br_tuned_test)\n","print('R2 score:', r2_br_tuned_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lAceWiCnw1DL","executionInfo":{"status":"ok","timestamp":1724539445227,"user_tz":300,"elapsed":35138,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"e16ac10b-713d-4102-b24c-953c71caf7a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["Best Parameters: {'alpha_1': 1e-06, 'alpha_2': 0.001, 'lambda_1': 0.001, 'lambda_2': 0.0001, 'max_iter': 100, 'tol': 0.0001}\n","MSE: 0.004099940273949911\n","MAE: 0.05115556256810553\n","RMSE: 0.06403077599053374\n","R2 score: 0.7654629159712586\n"]}]},{"cell_type":"markdown","source":["### Elastic Net"],"metadata":{"id":"AqtGRNv4wuqk"}},{"cell_type":"code","source":["# Define the Elastic Net model\n","elastic_net_model = ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42)\n","\n","# Train the model\n","elastic_net_model.fit(X_train, y_train)\n","\n","# Make predictions on the testing set\n","y_pred_en = elastic_net_model.predict(X_test)\n","\n","# Calculate the MSE, MAE, RMSE, and R² score on the testing set\n","mse_en_test = mean_squared_error(y_test, y_pred_en)\n","mae_en_test = mean_absolute_error(y_test, y_pred_en)\n","rmse_en_test = mean_squared_error(y_test, y_pred_en, squared=False)\n","r2_en_test = r2_score(y_test, y_pred_en)\n","\n","print('MSE:', mse_en_test)\n","print('MAE:', mae_en_test)\n","print('RMSE:', rmse_en_test)\n","print('R2 score:', r2_en_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Et5TTLXYw2TA","executionInfo":{"status":"ok","timestamp":1724539445387,"user_tz":300,"elapsed":163,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"8b9f5e48-b132-4679-a8b0-7b63a2447736"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE: 0.006927000712012644\n","MAE: 0.0676187829752003\n","RMSE: 0.08322860513076405\n","R2 score: 0.603740923158553\n"]}]},{"cell_type":"code","source":["# Tuned\n","# Define parameter grid\n","\n","# Define the parameter grid\n","param_grid = {\n","    'alpha': [0.1, 1.0, 10.0, 100.0],  # Regularization strength\n","    'l1_ratio': [0.1, 0.5, 0.7, 0.9, 1.0]  # Mix between L1 and L2 penalty\n","}\n","\n","# Set up GridSearchCV\n","grid_search_en = GridSearchCV(estimator=ElasticNet(random_state=42),\n","                              param_grid=param_grid,\n","                              cv=5,  # 5-fold cross-validation\n","                              scoring='neg_mean_squared_error',\n","                              n_jobs=-1)  # Use all available cores\n","\n","# Fit the model using grid search\n","grid_search_en.fit(X_train, y_train)\n","\n","# Get the best model from grid search\n","best_en_model = grid_search_en.best_estimator_\n","\n","# Make predictions on the testing set\n","y_pred_en_tuned = best_en_model.predict(X_test)\n","\n","# Calculate the MSE, MAE, RMSE, and R² score on the testing set\n","mse_en_tuned_test = mean_squared_error(y_test, y_pred_en_tuned)\n","mae_en_tuned_test = mean_absolute_error(y_test, y_pred_en_tuned)\n","rmse_en_tuned_test = mean_squared_error(y_test, y_pred_en_tuned, squared=False)\n","r2_en_tuned_test = r2_score(y_test, y_pred_en_tuned)\n","\n","print('Best Parameters:', grid_search_en.best_params_)\n","print('MSE:', mse_en_tuned_test)\n","print('MAE:', mae_en_tuned_test)\n","print('RMSE:', rmse_en_tuned_test)\n","print('R2 score:', r2_en_tuned_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LypQ3q3kw2WM","executionInfo":{"status":"ok","timestamp":1724539446898,"user_tz":300,"elapsed":1514,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"794fca91-1e09-45c0-fb31-7be31421d017"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Parameters: {'alpha': 0.1, 'l1_ratio': 0.1}\n","MSE: 0.0043147464440773465\n","MAE: 0.052412804820090114\n","RMSE: 0.06568672958883968\n","R2 score: 0.7531749289746739\n"]}]},{"cell_type":"markdown","source":["### ANN"],"metadata":{"id":"SIn3gzXFwwo4"}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)"],"metadata":{"id":"DU4A5B-dtkin"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the neural network architecture\n","ann_model = keras.Sequential([\n","    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n","    keras.layers.Dense(32, activation='relu'),\n","    keras.layers.Dense(1)  # Output layer with 1 neuron for EVI prediction\n","])\n","\n","# Compile the model\n","ann_model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Train the model\n","ann_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n","\n","# Evaluate the model\n","loss = ann_model.evaluate(X_test, y_test)\n","print(\"Test Loss:\", loss)\n","\n","# Make predictions\n","predictions = ann_model.predict(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ufQpuyY1hrRF","executionInfo":{"status":"ok","timestamp":1724539463999,"user_tz":300,"elapsed":10841,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"25438eac-db09-46df-b043-5bbf154e3c76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0592 - val_loss: 0.0183\n","Epoch 2/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0163 - val_loss: 0.0121\n","Epoch 3/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102 - val_loss: 0.0117\n","Epoch 4/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0094\n","Epoch 5/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0091\n","Epoch 6/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0065 - val_loss: 0.0086\n","Epoch 7/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - val_loss: 0.0096\n","Epoch 8/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0087\n","Epoch 9/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 - val_loss: 0.0077\n","Epoch 10/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0051 - val_loss: 0.0075\n","Epoch 11/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0076\n","Epoch 12/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0073\n","Epoch 13/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - val_loss: 0.0079\n","Epoch 14/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0074\n","Epoch 15/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0038 - val_loss: 0.0071\n","Epoch 16/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - val_loss: 0.0069\n","Epoch 17/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0035 - val_loss: 0.0068\n","Epoch 18/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0032 - val_loss: 0.0068\n","Epoch 19/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0068\n","Epoch 20/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0069\n","Epoch 21/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0073\n","Epoch 22/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0074\n","Epoch 23/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0036 - val_loss: 0.0066\n","Epoch 24/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0067\n","Epoch 25/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0027 - val_loss: 0.0064\n","Epoch 26/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - val_loss: 0.0068\n","Epoch 27/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0040 - val_loss: 0.0061\n","Epoch 28/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0040 - val_loss: 0.0059\n","Epoch 29/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - val_loss: 0.0059\n","Epoch 30/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - val_loss: 0.0060\n","Epoch 31/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0024 - val_loss: 0.0057\n","Epoch 32/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - val_loss: 0.0064\n","Epoch 33/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0068\n","Epoch 34/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0073\n","Epoch 35/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0059\n","Epoch 36/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0056\n","Epoch 37/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0059\n","Epoch 38/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0059\n","Epoch 39/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0064\n","Epoch 40/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0055\n","Epoch 41/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0056\n","Epoch 42/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0057\n","Epoch 43/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0068\n","Epoch 44/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0058\n","Epoch 45/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0058\n","Epoch 46/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0057\n","Epoch 47/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0057\n","Epoch 48/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0069 - val_loss: 0.0080\n","Epoch 49/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0058\n","Epoch 50/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0053\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 \n","Test Loss: 0.004388142377138138\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"]}]},{"cell_type":"code","source":["# Calculate evaluation metrics\n","mse = mean_squared_error(y_test, predictions)\n","mae = mean_absolute_error(y_test, predictions)\n","rmse = mean_squared_error(y_test, predictions, squared=False)\n","r2 = r2_score(y_test, predictions)\n","print('MSE:', mse)\n","print('RMSE:', rmse)\n","print('R2 score:', r2)\n","print('MAE:', mae)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KymdvBVPix0M","executionInfo":{"status":"ok","timestamp":1724539482358,"user_tz":300,"elapsed":178,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"5fdc1b3c-c1d8-4ff3-ec83-ca541e3e26a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE: 0.004388142585388876\n","RMSE: 0.06624305688439261\n","R2 score: 0.7489763026991786\n","MAE: 0.05081269991874695\n"]}]},{"cell_type":"code","source":["# Tuned\n","# Define parameter grid\n","# Could not do parameter grid because KerasRegressor could not be imported for grid search\n","\n","# Define the neural network architecture\n","tuned_ann_model = keras.Sequential([\n","    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n","    keras.layers.Dense(32, activation='relu'),\n","    keras.layers.Dense(1)  # Output layer with 1 neuron for EVI prediction\n","])\n","\n","# Compile the model\n","tuned_ann_model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Train the model\n","tuned_ann_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n","\n","# Evaluate the model\n","loss = tuned_ann_model.evaluate(X_test, y_test)\n","print(\"Test Loss:\", loss)\n","\n","# Make predictions\n","y_pred = tuned_ann_model.predict(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eHGRdxKHhrUp","executionInfo":{"status":"ok","timestamp":1724539500740,"user_tz":300,"elapsed":17513,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"7cac3f4e-6aa4-4c06-fc67-7fde3aaace8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0631 - val_loss: 0.0196\n","Epoch 2/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0129\n","Epoch 3/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0103 - val_loss: 0.0105\n","Epoch 4/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0089\n","Epoch 5/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0079\n","Epoch 6/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0071\n","Epoch 7/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0065 - val_loss: 0.0066\n","Epoch 8/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0061\n","Epoch 9/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0060\n","Epoch 10/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0055\n","Epoch 11/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0065\n","Epoch 12/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0045 - val_loss: 0.0056\n","Epoch 13/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0040 - val_loss: 0.0053\n","Epoch 14/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0033 - val_loss: 0.0055\n","Epoch 15/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - val_loss: 0.0060\n","Epoch 16/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - val_loss: 0.0063\n","Epoch 17/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0037 - val_loss: 0.0056\n","Epoch 18/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0054\n","Epoch 19/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0033 - val_loss: 0.0056\n","Epoch 20/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0033 - val_loss: 0.0056\n","Epoch 21/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 0.0065\n","Epoch 22/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0057\n","Epoch 23/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0053\n","Epoch 24/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0052\n","Epoch 25/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0051\n","Epoch 26/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0051\n","Epoch 27/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0052\n","Epoch 28/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0050\n","Epoch 29/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0050\n","Epoch 30/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0053\n","Epoch 31/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0050\n","Epoch 32/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0051\n","Epoch 33/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0049\n","Epoch 34/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0018 - val_loss: 0.0049\n","Epoch 35/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0049\n","Epoch 36/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - val_loss: 0.0047\n","Epoch 37/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0047\n","Epoch 38/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0020 - val_loss: 0.0050\n","Epoch 39/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - val_loss: 0.0047\n","Epoch 40/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - val_loss: 0.0054\n","Epoch 41/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0054\n","Epoch 42/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0050\n","Epoch 43/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - val_loss: 0.0049\n","Epoch 44/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0020 - val_loss: 0.0049\n","Epoch 45/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - val_loss: 0.0046\n","Epoch 46/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - val_loss: 0.0046\n","Epoch 47/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - val_loss: 0.0052\n","Epoch 48/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0036 - val_loss: 0.0057\n","Epoch 49/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0028 - val_loss: 0.0048\n","Epoch 50/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - val_loss: 0.0045\n","Epoch 51/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - val_loss: 0.0046\n","Epoch 52/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0048\n","Epoch 53/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0047\n","Epoch 54/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - val_loss: 0.0045\n","Epoch 55/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0019 - val_loss: 0.0045\n","Epoch 56/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0019 - val_loss: 0.0048\n","Epoch 57/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - val_loss: 0.0047\n","Epoch 58/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - val_loss: 0.0046\n","Epoch 59/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0046\n","Epoch 60/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 0.0052\n","Epoch 61/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - val_loss: 0.0062\n","Epoch 62/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - val_loss: 0.0047\n","Epoch 63/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - val_loss: 0.0050\n","Epoch 64/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 - val_loss: 0.0048\n","Epoch 65/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - val_loss: 0.0048\n","Epoch 66/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0048\n","Epoch 67/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - val_loss: 0.0047\n","Epoch 68/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - val_loss: 0.0050\n","Epoch 69/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0049\n","Epoch 70/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - val_loss: 0.0056\n","Epoch 71/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - val_loss: 0.0048\n","Epoch 72/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 - val_loss: 0.0054\n","Epoch 73/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - val_loss: 0.0048\n","Epoch 74/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0054\n","Epoch 75/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0016 - val_loss: 0.0046\n","Epoch 76/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 0.0046\n","Epoch 77/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - val_loss: 0.0045\n","Epoch 78/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - val_loss: 0.0043\n","Epoch 79/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0046\n","Epoch 80/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0044\n","Epoch 81/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - val_loss: 0.0047\n","Epoch 82/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0045\n","Epoch 83/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 0.0046\n","Epoch 84/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0046\n","Epoch 85/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - val_loss: 0.0044\n","Epoch 86/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - val_loss: 0.0044\n","Epoch 87/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - val_loss: 0.0046\n","Epoch 88/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - val_loss: 0.0046\n","Epoch 89/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - val_loss: 0.0043\n","Epoch 90/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - val_loss: 0.0047\n","Epoch 91/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0050\n","Epoch 92/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - val_loss: 0.0047\n","Epoch 93/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - val_loss: 0.0045\n","Epoch 94/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - val_loss: 0.0046\n","Epoch 95/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - val_loss: 0.0045\n","Epoch 96/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0012 - val_loss: 0.0045\n","Epoch 97/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - val_loss: 0.0043\n","Epoch 98/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0012 - val_loss: 0.0045\n","Epoch 99/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 0.0046\n","Epoch 100/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - val_loss: 0.0050\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0068 \n","Test Loss: 0.006136310752481222\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"]}]},{"cell_type":"code","source":["# Calculate regression metrics\n","mse_test = mean_squared_error(y_test, y_pred)\n","mae_test = mean_absolute_error(y_test, y_pred)\n","rmse_test = mean_squared_error(y_test, y_pred, squared=False)\n","r2_test = r2_score(y_test, y_pred)\n","\n","# Remember manual best parameters used\n","print('Test MSE:', mse_test)\n","print('Test MAE:', mae_test)\n","print('Test RMSE:', rmse_test)\n","print('Test R2 score:', r2_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D_kXjFeTjuQd","executionInfo":{"status":"ok","timestamp":1724539503210,"user_tz":300,"elapsed":132,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"042266a1-1349-4eb9-f5c3-ed3c78a94092"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MSE: 0.0061363106305693535\n","Test MAE: 0.059282654881477354\n","Test RMSE: 0.07833460685143798\n","Test R2 score: 0.6489723493943058\n"]}]},{"cell_type":"markdown","source":["### CNN"],"metadata":{"id":"-QsvUsA9wxn9"}},{"cell_type":"code","source":["# Define the CNN model\n","cnn_model = Sequential([\n","    Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], 1)),\n","    MaxPooling1D(2),\n","    Flatten(),\n","    Dense(64, activation='relu'),\n","    Dense(1)  # Output layer with 1 neuron for EVI prediction\n","])\n","\n","# Compile the model\n","cnn_model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Train the model\n","cnn_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n","\n","# Evaluate the model\n","loss = cnn_model.evaluate(X_test, y_test)\n","print(\"Test Loss:\", loss)\n","\n","# Make predictions\n","predictions = cnn_model.predict(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fpinGSfQhe-g","executionInfo":{"status":"ok","timestamp":1724539523192,"user_tz":300,"elapsed":11851,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"84c52f7d-566b-4bd2-fb53-37c6f8e2813d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0979 - val_loss: 0.0135\n","Epoch 2/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - val_loss: 0.0092\n","Epoch 3/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072 - val_loss: 0.0063\n","Epoch 4/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0058\n","Epoch 5/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0053\n","Epoch 6/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0057\n","Epoch 7/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0055\n","Epoch 8/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0053\n","Epoch 9/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0051\n","Epoch 10/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0053\n","Epoch 11/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0049 - val_loss: 0.0062\n","Epoch 12/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0063 - val_loss: 0.0054\n","Epoch 13/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0048 - val_loss: 0.0051\n","Epoch 14/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - val_loss: 0.0050\n","Epoch 15/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0055\n","Epoch 16/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0060\n","Epoch 17/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0061 - val_loss: 0.0047\n","Epoch 18/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0049\n","Epoch 19/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0050\n","Epoch 20/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0049\n","Epoch 21/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0047\n","Epoch 22/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0047\n","Epoch 23/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0046\n","Epoch 24/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0044 - val_loss: 0.0044\n","Epoch 25/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0046\n","Epoch 26/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0048\n","Epoch 27/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0047\n","Epoch 28/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0053\n","Epoch 29/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0050\n","Epoch 30/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0047\n","Epoch 31/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 - val_loss: 0.0047\n","Epoch 32/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0036 - val_loss: 0.0046\n","Epoch 33/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0031 - val_loss: 0.0046\n","Epoch 34/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0055\n","Epoch 35/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0040 - val_loss: 0.0044\n","Epoch 36/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0040 - val_loss: 0.0048\n","Epoch 37/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0046\n","Epoch 38/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - val_loss: 0.0056\n","Epoch 39/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0054\n","Epoch 40/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0040 - val_loss: 0.0044\n","Epoch 41/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0035 - val_loss: 0.0051\n","Epoch 42/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0055\n","Epoch 43/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0046\n","Epoch 44/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - val_loss: 0.0043\n","Epoch 45/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0046\n","Epoch 46/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0045\n","Epoch 47/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0033 - val_loss: 0.0046\n","Epoch 48/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0035 - val_loss: 0.0045\n","Epoch 49/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0051\n","Epoch 50/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0027 - val_loss: 0.0047\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043 \n","Test Loss: 0.003977243322879076\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d1765517760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"]}]},{"cell_type":"code","source":["# Calculate evaluation metrics\n","mse = mean_squared_error(y_test, predictions)\n","mae = mean_absolute_error(y_test, predictions)\n","rmse = mean_squared_error(y_test, predictions, squared=False)\n","r2 = r2_score(y_test, predictions)\n","print('MSE:', mse)\n","print('RMSE:', rmse)\n","print('R2 score:', r2)\n","print('MAE:', mae)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VTA-3G4wkGm8","executionInfo":{"status":"ok","timestamp":1724539528799,"user_tz":300,"elapsed":171,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"e4dd0d91-06d6-414b-88ae-0893d1d36947"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE: 0.003977243141903594\n","RMSE: 0.0630653878280598\n","R2 score: 0.772481805429643\n","MAE: 0.048462953539192666\n"]}]},{"cell_type":"code","source":["# Tuned\n","# Define parameter grid\n","\n","# Define the CNN model\n","tuned_cnn_model = Sequential([\n","    Conv1D(32, 3, activation='relu', input_shape=(X_train.shape[1], 1)),\n","    MaxPooling1D(2),\n","    Flatten(),\n","    Dense(64, activation='relu'),\n","    Dense(1)  # Output layer with 1 neuron for EVI prediction\n","])\n","\n","# Compile the model\n","tuned_cnn_model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Train the model\n","tuned_cnn_model.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.2)\n","\n","# Evaluate the model\n","loss = tuned_cnn_model.evaluate(X_test, y_test)\n","print(\"Test Loss:\", loss)\n","\n","# Make predictions\n","y_pred = tuned_cnn_model.predict(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ak3XP5E0hfEQ","executionInfo":{"status":"ok","timestamp":1724539535574,"user_tz":300,"elapsed":5823,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"fdace114-ecc8-4f8c-afed-6c5e6197eda4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0550 - val_loss: 0.0075\n","Epoch 2/15\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0090 - val_loss: 0.0066\n","Epoch 3/15\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0065 - val_loss: 0.0055\n","Epoch 4/15\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056 - val_loss: 0.0068\n","Epoch 5/15\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0055\n","Epoch 6/15\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0058\n","Epoch 7/15\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0054\n","Epoch 8/15\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0044 - val_loss: 0.0053\n","Epoch 9/15\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0050 - val_loss: 0.0056\n","Epoch 10/15\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0060\n","Epoch 11/15\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0064\n","Epoch 12/15\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0053\n","Epoch 13/15\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0043 - val_loss: 0.0057\n","Epoch 14/15\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0052\n","Epoch 15/15\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0054\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045 \n","Test Loss: 0.004315461032092571\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d1765c643a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"]}]},{"cell_type":"code","source":["# Calculate regression metrics\n","mse_test = mean_squared_error(y_test, y_pred)\n","mae_test = mean_absolute_error(y_test, y_pred)\n","rmse_test = mean_squared_error(y_test, y_pred, squared=False)\n","r2_test = r2_score(y_test, y_pred)\n","\n","print('Test MSE:', mse_test)\n","print('Test MAE:', mae_test)\n","print('Test RMSE:', rmse_test)\n","print('Test R2 score:', r2_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0St4SPRlnH2s","executionInfo":{"status":"ok","timestamp":1724539541462,"user_tz":300,"elapsed":149,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"a04ed9bf-d1e0-471a-c04f-8ed689a327af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MSE: 0.004315461073983803\n","Test MAE: 0.05125590820252895\n","Test RMSE: 0.06569216904611845\n","Test R2 score: 0.7531340485707604\n"]}]},{"cell_type":"markdown","source":["### RNN"],"metadata":{"id":"29UpR1dywymi"}},{"cell_type":"code","source":["# Reshape input data for RNN\n","X_train_rnn = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n","X_test_rnn = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])"],"metadata":{"id":"kIO2Xa-dwX0X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the RNN model\n","rnn_model = Sequential([\n","    SimpleRNN(64, activation='relu', input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), return_sequences=True),\n","    SimpleRNN(32, activation='relu'),\n","    Dense(1)  # Output layer with 1 neuron for EVI prediction\n","])\n","\n","# Compile the model\n","rnn_model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Train the model\n","rnn_model.fit(X_train_rnn, y_train, epochs=50, batch_size=32, validation_split=0.2)\n","\n","# Evaluate the model\n","loss = rnn_model.evaluate(X_test_rnn, y_test)\n","print(\"Test Loss:\", loss)\n","\n","# Make predictions\n","predictions = rnn_model.predict(X_test_rnn)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_yc6imt8w405","executionInfo":{"status":"ok","timestamp":1724539561296,"user_tz":300,"elapsed":13485,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"ef062620-aa31-4d01-cf75-b9564d988446"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.2504 - val_loss: 0.0426\n","Epoch 2/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0306 - val_loss: 0.0211\n","Epoch 3/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0135 - val_loss: 0.0167\n","Epoch 4/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0109 - val_loss: 0.0134\n","Epoch 5/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0126\n","Epoch 6/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0071 - val_loss: 0.0111\n","Epoch 7/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0073 - val_loss: 0.0114\n","Epoch 8/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0107\n","Epoch 9/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0100\n","Epoch 10/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0098\n","Epoch 11/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0055 - val_loss: 0.0110\n","Epoch 12/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0093\n","Epoch 13/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0045 - val_loss: 0.0082\n","Epoch 14/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0094\n","Epoch 15/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0103\n","Epoch 16/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0086\n","Epoch 17/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0089\n","Epoch 18/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0045 - val_loss: 0.0076\n","Epoch 19/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0076\n","Epoch 20/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0091\n","Epoch 21/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0070\n","Epoch 22/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0068\n","Epoch 23/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0069\n","Epoch 24/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0069\n","Epoch 25/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0067\n","Epoch 26/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0076\n","Epoch 27/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0068\n","Epoch 28/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0031 - val_loss: 0.0090\n","Epoch 29/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0051 - val_loss: 0.0075\n","Epoch 30/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0032 - val_loss: 0.0068\n","Epoch 31/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0029 - val_loss: 0.0074\n","Epoch 32/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0081\n","Epoch 33/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0068\n","Epoch 34/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0079\n","Epoch 35/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0068\n","Epoch 36/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0070\n","Epoch 37/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 - val_loss: 0.0071\n","Epoch 38/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - val_loss: 0.0067\n","Epoch 39/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0073\n","Epoch 40/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0088\n","Epoch 41/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0028 - val_loss: 0.0074\n","Epoch 42/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0069\n","Epoch 43/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0025 - val_loss: 0.0069\n","Epoch 44/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0026 - val_loss: 0.0069\n","Epoch 45/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0065\n","Epoch 46/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - val_loss: 0.0068\n","Epoch 47/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0066\n","Epoch 48/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0069\n","Epoch 49/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0040 - val_loss: 0.0071\n","Epoch 50/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - val_loss: 0.0069\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0057 \n","Test Loss: 0.005406756419688463\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step\n"]}]},{"cell_type":"code","source":["# Calculate evaluation metrics\n","mse = mean_squared_error(y_test, predictions)\n","mae = mean_absolute_error(y_test, predictions)\n","rmse = mean_squared_error(y_test, predictions, squared=False)\n","r2 = r2_score(y_test, predictions)\n","print('MSE:', mse)\n","print('RMSE:', rmse)\n","print('R2 score:', r2)\n","print('MAE:', mae)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LuTzrisYnqOe","executionInfo":{"status":"ok","timestamp":1724539569080,"user_tz":300,"elapsed":153,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"7bf11d5e-bdac-4244-9adc-f678e8486be0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE: 0.0054067566208485345\n","RMSE: 0.07353065089368198\n","R2 score: 0.6907064866373712\n","MAE: 0.05827935701012612\n"]}]},{"cell_type":"code","source":["# Tuned\n","# Define parameter grid\n","\n","# Define the RNN model\n","tuned_rnn_model = Sequential([\n","    SimpleRNN(64, activation='relu', input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), return_sequences=True),\n","    SimpleRNN(32, activation='relu'),\n","    Dense(1)  # Output layer with 1 neuron for EVI prediction\n","])\n","\n","# Compile the model\n","tuned_rnn_model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Train the model\n","tuned_rnn_model.fit(X_train_rnn, y_train, epochs=110, batch_size=32, validation_split=0.2)\n","\n","# Evaluate the model\n","loss = tuned_rnn_model.evaluate(X_test_rnn, y_test)\n","print(\"Test Loss:\", loss)\n","\n","# Make predictions\n","y_pred = tuned_rnn_model.predict(X_test_rnn)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fXv2lSgw44g","executionInfo":{"status":"ok","timestamp":1724539596432,"user_tz":300,"elapsed":25016,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"8ac0aec8-89e0-4c30-c68f-a97fd6380d97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/110\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 0.0924 - val_loss: 0.0397\n","Epoch 2/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0302 - val_loss: 0.0204\n","Epoch 3/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0157 - val_loss: 0.0138\n","Epoch 4/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0117 - val_loss: 0.0120\n","Epoch 5/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0108\n","Epoch 6/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0100\n","Epoch 7/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0100\n","Epoch 8/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0101\n","Epoch 9/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0091\n","Epoch 10/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0054 - val_loss: 0.0086\n","Epoch 11/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0085\n","Epoch 12/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0079\n","Epoch 13/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0073\n","Epoch 14/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0076\n","Epoch 15/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0077\n","Epoch 16/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0078\n","Epoch 17/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0075\n","Epoch 18/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0042 - val_loss: 0.0071\n","Epoch 19/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0067 - val_loss: 0.0074\n","Epoch 20/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0067\n","Epoch 21/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0065\n","Epoch 22/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0034 - val_loss: 0.0068\n","Epoch 23/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0069\n","Epoch 24/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0037 - val_loss: 0.0065\n","Epoch 25/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0063\n","Epoch 26/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0065\n","Epoch 27/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0064\n","Epoch 28/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0062\n","Epoch 29/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0063\n","Epoch 30/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0061\n","Epoch 31/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0024 - val_loss: 0.0067\n","Epoch 32/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0065\n","Epoch 33/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0065\n","Epoch 34/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0062\n","Epoch 35/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0064\n","Epoch 36/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0062\n","Epoch 37/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0062\n","Epoch 38/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0062\n","Epoch 39/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0023 - val_loss: 0.0059\n","Epoch 40/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0060\n","Epoch 41/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0065\n","Epoch 42/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0060\n","Epoch 43/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0020 - val_loss: 0.0061\n","Epoch 44/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0062\n","Epoch 45/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0019 - val_loss: 0.0062\n","Epoch 46/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0065\n","Epoch 47/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0067\n","Epoch 48/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 0.0063\n","Epoch 49/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0066\n","Epoch 50/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0061\n","Epoch 51/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0059\n","Epoch 52/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0062\n","Epoch 53/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - val_loss: 0.0058\n","Epoch 54/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0021 - val_loss: 0.0062\n","Epoch 55/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0019 - val_loss: 0.0064\n","Epoch 56/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0022 - val_loss: 0.0068\n","Epoch 57/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0061\n","Epoch 58/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0061\n","Epoch 59/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0019 - val_loss: 0.0060\n","Epoch 60/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0021 - val_loss: 0.0056\n","Epoch 61/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0018 - val_loss: 0.0058\n","Epoch 62/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0060\n","Epoch 63/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0017 - val_loss: 0.0060\n","Epoch 64/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0061\n","Epoch 65/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 0.0058\n","Epoch 66/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0016 - val_loss: 0.0057\n","Epoch 67/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0015 - val_loss: 0.0058\n","Epoch 68/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0017 - val_loss: 0.0059\n","Epoch 69/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 0.0057\n","Epoch 70/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0058\n","Epoch 71/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0058\n","Epoch 72/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0016 - val_loss: 0.0058\n","Epoch 73/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0060\n","Epoch 74/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0056\n","Epoch 75/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - val_loss: 0.0062\n","Epoch 76/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - val_loss: 0.0063\n","Epoch 77/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - val_loss: 0.0058\n","Epoch 78/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0060\n","Epoch 79/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0058\n","Epoch 80/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0058\n","Epoch 81/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0057\n","Epoch 82/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0057\n","Epoch 83/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0059\n","Epoch 84/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0066\n","Epoch 85/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0057 - val_loss: 0.0071\n","Epoch 86/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0051 - val_loss: 0.0070\n","Epoch 87/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0063\n","Epoch 88/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0018 - val_loss: 0.0059\n","Epoch 89/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0015 - val_loss: 0.0060\n","Epoch 90/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 0.0058\n","Epoch 91/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0014 - val_loss: 0.0060\n","Epoch 92/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0016 - val_loss: 0.0057\n","Epoch 93/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 0.0054\n","Epoch 94/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - val_loss: 0.0054\n","Epoch 95/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 0.0059\n","Epoch 96/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0017 - val_loss: 0.0060\n","Epoch 97/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 0.0057\n","Epoch 98/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - val_loss: 0.0056\n","Epoch 99/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 0.0059\n","Epoch 100/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 0.0059\n","Epoch 101/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 0.0058\n","Epoch 102/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 0.0053\n","Epoch 103/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 0.0055\n","Epoch 104/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0013 - val_loss: 0.0058\n","Epoch 105/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0015 - val_loss: 0.0058\n","Epoch 106/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0011 - val_loss: 0.0055\n","Epoch 107/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - val_loss: 0.0056\n","Epoch 108/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0011 - val_loss: 0.0056\n","Epoch 109/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0014 - val_loss: 0.0058\n","Epoch 110/110\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0013 - val_loss: 0.0054\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 \n","Test Loss: 0.005326798185706139\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n"]}]},{"cell_type":"code","source":["# Calculate regression metrics\n","mse_test = mean_squared_error(y_test, y_pred)\n","mae_test = mean_absolute_error(y_test, y_pred)\n","rmse_test = mean_squared_error(y_test, y_pred, squared=False)\n","r2_test = r2_score(y_test, y_pred)\n","\n","print('Test MSE:', mse_test)\n","print('Test MAE:', mae_test)\n","print('Test RMSE:', rmse_test)\n","print('Test R2 score:', r2_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IdQdFLNyn7T1","executionInfo":{"status":"ok","timestamp":1724539607606,"user_tz":300,"elapsed":131,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"21dcb3bb-7aa4-4158-a6a0-2d7a2ae35ca0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MSE: 0.005326798284126751\n","Test MAE: 0.0553848849710822\n","Test RMSE: 0.07298491819634212\n","Test R2 score: 0.6952805033023624\n"]}]},{"cell_type":"markdown","source":["### LSTM"],"metadata":{"id":"trH8ePQcwzqy"}},{"cell_type":"code","source":["# Define the LSTM model\n","timesteps=1\n","X_train_lstm = X_train.reshape(X_train.shape[0], timesteps, X_train.shape[1])\n","X_test_lstm = X_test.reshape(X_test.shape[0], timesteps, X_test.shape[1])\n","\n","lstm_model = Sequential([\n","    LSTM(64, activation='relu', input_shape=(timesteps, X_train_lstm.shape[2]), return_sequences=True),\n","    LSTM(32, activation='relu'),\n","    Dense(1)  # Output layer with 1 neuron for GPP prediction\n","])\n","\n","# Compile the model\n","lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Train the model\n","lstm_model.fit(X_train_lstm, y_train, epochs=50, batch_size=32, validation_split=0.2)\n","\n","# Evaluate the model\n","loss = lstm_model.evaluate(X_test_lstm, y_test)\n","print(\"Test Loss:\", loss)\n","\n","# Make predictions\n","predictions = lstm_model.predict(X_test_lstm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iJOC-Py0wtsp","executionInfo":{"status":"ok","timestamp":1724539625668,"user_tz":300,"elapsed":16792,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"f2cb4240-52c7-4395-c701-a95f47918ea1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 0.1032 - val_loss: 0.0743\n","Epoch 2/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0492 - val_loss: 0.0225\n","Epoch 3/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0165 - val_loss: 0.0086\n","Epoch 4/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0070\n","Epoch 5/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0057\n","Epoch 6/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0049\n","Epoch 7/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0046\n","Epoch 8/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0045 - val_loss: 0.0044\n","Epoch 9/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0043 - val_loss: 0.0043\n","Epoch 10/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0045 - val_loss: 0.0042\n","Epoch 11/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0043\n","Epoch 12/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0042\n","Epoch 13/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0041\n","Epoch 14/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0042 - val_loss: 0.0040\n","Epoch 15/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0039 - val_loss: 0.0041\n","Epoch 16/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0041\n","Epoch 17/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0041\n","Epoch 18/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0042\n","Epoch 19/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0044\n","Epoch 20/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0033 - val_loss: 0.0043\n","Epoch 21/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0041\n","Epoch 22/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0037 - val_loss: 0.0040\n","Epoch 23/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - val_loss: 0.0041\n","Epoch 24/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0035 - val_loss: 0.0042\n","Epoch 25/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0041\n","Epoch 26/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0037 - val_loss: 0.0042\n","Epoch 27/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 0.0042\n","Epoch 28/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0041\n","Epoch 29/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0041\n","Epoch 30/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0047\n","Epoch 31/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0044\n","Epoch 32/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0042\n","Epoch 33/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0031 - val_loss: 0.0041\n","Epoch 34/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0043\n","Epoch 35/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0042\n","Epoch 36/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0046\n","Epoch 37/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - val_loss: 0.0043\n","Epoch 38/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0046\n","Epoch 39/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0042\n","Epoch 40/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0043\n","Epoch 41/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0043\n","Epoch 42/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0043\n","Epoch 43/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0042\n","Epoch 44/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0042\n","Epoch 45/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0042\n","Epoch 46/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0026 - val_loss: 0.0042\n","Epoch 47/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0024 - val_loss: 0.0042\n","Epoch 48/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0031 - val_loss: 0.0045\n","Epoch 49/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0041\n","Epoch 50/50\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0044\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0033 \n","Test Loss: 0.0031977263279259205\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step\n"]}]},{"cell_type":"code","source":["# Calculate evaluation metrics\n","mse = mean_squared_error(y_test, predictions)\n","mae = mean_absolute_error(y_test, predictions)\n","rmse = mean_squared_error(y_test, predictions, squared=False)\n","r2 = r2_score(y_test, predictions)\n","print('MSE:', mse)\n","print('RMSE:', rmse)\n","print('R2 score:', r2)\n","print('MAE:', mae)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9xcbI8ttqoiq","executionInfo":{"status":"ok","timestamp":1724539629028,"user_tz":300,"elapsed":150,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"9552af26-d652-48af-c97d-44ce5e2baaf0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE: 0.00319772667077756\n","RMSE: 0.05654844534359508\n","R2 score: 0.8170740452854054\n","MAE: 0.04299417999446392\n"]}]},{"cell_type":"code","source":["# Tuned\n","# Define parameter grid\n","\n","tuned_lstm_model = Sequential([\n","    LSTM(64, activation='relu', input_shape=(timesteps, X_train_lstm.shape[2]), return_sequences=True),\n","    LSTM(32, activation='relu'),\n","    Dense(1)  # Output layer with 1 neuron for GPP prediction\n","])\n","\n","# Compile the model\n","tuned_lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# Train the model\n","tuned_lstm_model.fit(X_train_lstm, y_train, epochs=100, batch_size=32, validation_split=0.2)\n","\n","# Evaluate the model\n","loss = tuned_lstm_model.evaluate(X_test_lstm, y_test)\n","print(\"Test Loss:\", loss)\n","\n","# Make predictions\n","y_pred = tuned_lstm_model.predict(X_test_lstm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LBEdfboawi0Z","executionInfo":{"status":"ok","timestamp":1724539659549,"user_tz":300,"elapsed":29222,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"e018dbc6-6e2a-486c-e54b-d81f9e8f65d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - loss: 0.0938 - val_loss: 0.0593\n","Epoch 2/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0424 - val_loss: 0.0176\n","Epoch 3/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0151 - val_loss: 0.0068\n","Epoch 4/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0068 - val_loss: 0.0055\n","Epoch 5/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0051\n","Epoch 6/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0048\n","Epoch 7/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0046\n","Epoch 8/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0045\n","Epoch 9/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0044\n","Epoch 10/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0041 - val_loss: 0.0043\n","Epoch 11/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0042 - val_loss: 0.0043\n","Epoch 12/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0039 - val_loss: 0.0044\n","Epoch 13/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0040 - val_loss: 0.0043\n","Epoch 14/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0043\n","Epoch 15/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0042\n","Epoch 16/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - val_loss: 0.0042\n","Epoch 17/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - val_loss: 0.0041\n","Epoch 18/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0041\n","Epoch 19/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0045\n","Epoch 20/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0042\n","Epoch 21/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0042\n","Epoch 22/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0041\n","Epoch 23/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0045\n","Epoch 24/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0042\n","Epoch 25/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0035 - val_loss: 0.0041\n","Epoch 26/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0046\n","Epoch 27/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0043\n","Epoch 28/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0043\n","Epoch 29/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0043\n","Epoch 30/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0042\n","Epoch 31/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0036 - val_loss: 0.0043\n","Epoch 32/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0043\n","Epoch 33/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0033 - val_loss: 0.0042\n","Epoch 34/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0043\n","Epoch 35/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0045\n","Epoch 36/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0043\n","Epoch 37/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0043\n","Epoch 38/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0034 - val_loss: 0.0043\n","Epoch 39/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0032 - val_loss: 0.0042\n","Epoch 40/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0043\n","Epoch 41/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0044\n","Epoch 42/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0043\n","Epoch 43/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0030 - val_loss: 0.0044\n","Epoch 44/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0044\n","Epoch 45/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0045\n","Epoch 46/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - val_loss: 0.0042\n","Epoch 47/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0046\n","Epoch 48/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028 - val_loss: 0.0045\n","Epoch 49/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0043\n","Epoch 50/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0028 - val_loss: 0.0044\n","Epoch 51/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0030 - val_loss: 0.0043\n","Epoch 52/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0044\n","Epoch 53/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - val_loss: 0.0044\n","Epoch 54/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0046\n","Epoch 55/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0044\n","Epoch 56/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0026 - val_loss: 0.0043\n","Epoch 57/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 0.0043\n","Epoch 58/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0043\n","Epoch 59/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0042\n","Epoch 60/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 0.0042\n","Epoch 61/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0025 - val_loss: 0.0042\n","Epoch 62/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0043\n","Epoch 63/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0051\n","Epoch 64/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0045\n","Epoch 65/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0032 - val_loss: 0.0043\n","Epoch 66/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0028 - val_loss: 0.0044\n","Epoch 67/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0043\n","Epoch 68/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0042\n","Epoch 69/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0043\n","Epoch 70/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0043\n","Epoch 71/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0042\n","Epoch 72/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0043\n","Epoch 73/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0045\n","Epoch 74/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0042\n","Epoch 75/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0027 - val_loss: 0.0042\n","Epoch 76/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0030 - val_loss: 0.0041\n","Epoch 77/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0027 - val_loss: 0.0041\n","Epoch 78/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0030 - val_loss: 0.0044\n","Epoch 79/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0025 - val_loss: 0.0042\n","Epoch 80/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0041\n","Epoch 81/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0024 - val_loss: 0.0041\n","Epoch 82/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0042\n","Epoch 83/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - val_loss: 0.0040\n","Epoch 84/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0042\n","Epoch 85/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0041\n","Epoch 86/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0025 - val_loss: 0.0043\n","Epoch 87/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0021 - val_loss: 0.0043\n","Epoch 88/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0029 - val_loss: 0.0046\n","Epoch 89/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0048\n","Epoch 90/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0043\n","Epoch 91/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0025 - val_loss: 0.0042\n","Epoch 92/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0020 - val_loss: 0.0046\n","Epoch 93/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0036 - val_loss: 0.0049\n","Epoch 94/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0023 - val_loss: 0.0046\n","Epoch 95/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0044\n","Epoch 96/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0043\n","Epoch 97/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0023 - val_loss: 0.0042\n","Epoch 98/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0042\n","Epoch 99/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - val_loss: 0.0044\n","Epoch 100/100\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0022 - val_loss: 0.0044\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0034 \n","Test Loss: 0.00330618629232049\n","\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n"]}]},{"cell_type":"code","source":["# Calculate regression metrics\n","mse_test = mean_squared_error(y_test, y_pred)\n","mae_test = mean_absolute_error(y_test, y_pred)\n","rmse_test = mean_squared_error(y_test, y_pred, squared=False)\n","r2_test = r2_score(y_test, y_pred)\n","\n","print('Test MSE:', mse_test)\n","print('Test MAE:', mae_test)\n","print('Test RMSE:', rmse_test)\n","print('Test R2 score:', r2_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D9Ofdulwp9AB","executionInfo":{"status":"ok","timestamp":1724539673145,"user_tz":300,"elapsed":149,"user":{"displayName":"Catherine G. G. Donner","userId":"04948323668714127312"}},"outputId":"1408ce02-c71f-4721-d72c-cf34ee8176bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test MSE: 0.0033061862340365237\n","Test MAE: 0.04336923230230809\n","Test RMSE: 0.05749944551068752\n","Test R2 score: 0.8108696159517845\n"]}]},{"cell_type":"markdown","source":["## Saving Models"],"metadata":{"id":"Va1Y7RQhyUr5"}},{"cell_type":"code","source":["import pickle\n","\n","# Save non-tuned and tuned models\n","models_base_path = 'Modeling VIs in Tallgrass/models/evi/'\n","\n","with open(models_base_path + 'bayesian_ridge_evi.pkl', 'wb') as file:\n","    pickle.dump(bayesian_ridge_model, file)\n","\n","with open(models_base_path + 'tuned_br_evi.pkl', 'wb') as file:\n","    pickle.dump(tuned_br_best_model, file)\n","\n","with open(models_base_path + 'elastic_net_evi.pkl', 'wb') as file:\n","    pickle.dump(elastic_net_model, file)\n","\n","with open(models_base_path + 'tuned_en_evi.pkl', 'wb') as file:\n","    pickle.dump(best_en_model, file)\n","\n","with open(models_base_path + 'ann_evi.pkl', 'wb') as file:\n","    pickle.dump(ann_model, file)\n","\n","with open(models_base_path + 'tuned_ann_evi.pkl', 'wb') as file:\n","    pickle.dump(tuned_ann_model, file)\n","\n","with open(models_base_path + 'cnn_evi.pkl', 'wb') as file:\n","    pickle.dump(cnn_model, file)\n","\n","with open(models_base_path + 'tuned_cnn_evi.pkl', 'wb') as file:\n","    pickle.dump(tuned_cnn_model, file)\n","\n","with open(models_base_path + 'rnn_evi.pkl', 'wb') as file:\n","    pickle.dump(rnn_model, file)\n","\n","with open(models_base_path + 'tuned_rnn_evi.pkl', 'wb') as file:\n","    pickle.dump(tuned_rnn_model, file)\n","\n","with open(models_base_path + 'lstm_evi.pkl', 'wb') as file:\n","    pickle.dump(lstm_model, file)\n","\n","with open(models_base_path + 'tuned_lstm_evi.pkl', 'wb') as file:\n","    pickle.dump(tuned_lstm_model, file)"],"metadata":{"id":"tKZ84sb3yWAT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# End of code 8/24/24"],"metadata":{"id":"fIrEw2uXyWH7"},"execution_count":null,"outputs":[]}]}